
## 模型评估


### 1. 基本概念

为什么做模型评估？
- 验证模型有效性
- 发现改进方向
- 比较不同模型

模型评估三要素：
- 数据
- 指标
- 方法
#### 1.1 常见模型评估问题
##### 🔹 训练误差 VS 测试误差

##### 🔹 偏差与方差（Bias-Variance）

##### 🔹 过拟合与欠拟合

过度拟合(Overfitting): 训练集表现极佳, 但测试集表现差（泛化能力弱）

欠拟合： 训练和测试误差均高

##### 🔹外推失败（Extrapolation Error）
 模型在训练数据范围之外进行预测时失效。
 如，模型在`[0,10]`的数据区间训练，然后去预测大于100的测试数据。


##### 🔹 指标矛盾
不同评估指标结果不一致，如准确率高但召回率低。

##### 🔹 跨域泛化差
 在训练分布外的数据上表现骤降，如不同医院的医疗数据



### 2. 模型评估指标

#### 2.1 回归任务的评估指标

##### 🔹均方误差 MSE
预测值 与 真实值 误差平方和 取平均数。
值越低，说明预测误差越小。MSE=0表示能完全正确预测。

###### 1️⃣ <font style="background-color:tomato; color:black">残差平方和 SSR</font>
目标： 找到一条直线（或超平面），使得所有数据点的预测误差平方和最小。

一种线性回归的<font style="background-color:yellow; color:black">Loss function</font>
可用于衡量模型预测是否准确，回归线是否更贴合真实数据。

公式：

$$\text{SSR} = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$
- 实际值 $y_i$
- 预测值  $\hat{y}_i=β_0+β_1x_{i1}+⋯+βpxipy^​i​=β_0​+β_1​ x_{i1​}+⋯+βp​xip​$ 是预测值
- 残差（residual）是实际值与预测值之间的差异

 ###### 2️⃣ <font style="background-color: tomato; color:black">均方误差 MSE (Mean Squared Error)</font>
$$\text{MSE} = \frac{1}{n} \sum_{i=1}^{n}(y_i - \hat{y}_i)^2 = \frac{\text{RSS}}{n}$$
均方误差MSE 是残差平方和的平均值

```python
y_pred = model.predict(X_test)  
mse_score = mean_squared_error(y_test, y_pred)
```

##### 🔹  $R^2$ 分数 / 决定系数 (Coefficient of Determination)
衡量模型解释数据方差的能力。
值越接近于1越好。

- **R² = 1** 表示完美拟合，模型可以完全解释数据。
- **R² = 0** 表示模型跟简单用**均值**预测差不多，没什么用
- **R² < 0**（负数）则是模型比直接用均值还烂

```python
y_pred = model.predict(X_test)  
mse_score = model.score(y_test, y_pred)
```
##### 🔹 均方根误差 RMSE
##### 🔹 平均绝对误差 MAE
##### 🔹 决定系统 $R^2$ (Coefficient of Determination)

##### 🔹 残差分析 (Residual Analysis)
- 残差平方和 SSR
- 残差图 Residual Plot
##### 🔹 外推误差检测


#### 2.2 分类任务的评估指标

##### 🔹准确率Accuracy
##### 🔹 精准率 Precision
##### 🔹 召回率 Recall
##### 🔹 F1-Score

##### 🔹 混淆矩阵 Confusion Matrix

##### 🔹 AUC-ROC 曲线

##### 🔹 Log-Loss /  Cross-Entropy 损失


#### 2.3 多标签分类评估 Marco/Micro Averaging
#### 2.4 序列/时间序列评估 Rolling Forecast
#### 2.5 图像/生成模型评估
- FID
- IS
- PSNR
- SSIM

### 3. 模型验证方法

#### 3.1 训练集/验证集/测试集划分


#### 3.2 交叉验证（cross-validation）

##### 🔹 K 折交叉验证 K-Fold
##### 🔹 留一法 Leave-One-Out

##### 🔹 分层采样 Stratified Sampling

#### 3.3 自助法 Bootstrapping
#### 3.4 提前停止 Early Stopping



### 4. 模型选型与比较

#### 4.1 超参数调优
- Grid Search
- Random Search
#### 4.2 学习曲线分析
#### 4.3 模型泛化能力对比

#### 4.4 模型复杂度控制
正则化L1/L2

 

### 5. 可视化工具支持

#### 5.1 可视化工具
- Matplotlib
- Seaborn
- TensorBoard
#### 5.2 模型评估框架
- Scikit-learn
- Keras
- Metrics
#### 5.3 自动评估平台
- wandb
- MLFlow
- Comet


