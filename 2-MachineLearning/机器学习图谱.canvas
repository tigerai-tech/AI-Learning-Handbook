{
	"nodes":[
		{"id":"11","type":"text","text":"# 贝叶斯方法\n\n## 朴素贝叶斯\n- 高斯朴素贝叶斯\n- 多项式朴素贝叶斯\n- 伯努利朴素贝叶斯\n\n## 贝叶斯网络\n\n## 贝叶斯优化\n\n## 先验与后验\n\n## 最大似然估计(MLE)\n\n## 最大后验估计(MAP)","x":1440,"y":-635,"width":400,"height":300},
		{"id":"18","type":"text","text":"# 强化学习进阶\n\n## 模型基础\n- 马尔可夫决策过程(MDP)\n- 贝尔曼方程\n- 时序差分(TD)学习\n\n## 高级算法\n- 模仿学习(Imitation Learning)\n- 逆强化学习(IRL)\n- 多智能体强化学习\n- 分层强化学习\n- 元强化学习\n\n## 实际应用\n- 游戏AI\n- 机器人控制\n- 推荐系统\n- 资源调度\n- 自动驾驶","x":1440,"y":631,"width":400,"height":222},
		{"id":"17","type":"text","text":"# 强化学习\n\n## 基本概念\n- 智能体(Agent)\n- 环境(Environment)\n- 状态(State)\n- 动作(Action)\n- 奖励(Reward)\n- 策略(Policy)\n- 价值函数(Value Function)\n\n## 算法分类\n- 基于价值的方法\n  - Q-Learning\n  - DQN(Deep Q-Network)\n- 基于策略的方法\n  - 策略梯度(Policy Gradient)\n  - REINFORCE\n- 演员-评论家(Actor-Critic)方法\n  - A2C/A3C\n  - PPO\n  - DDPG\n  - SAC\n\n## 探索与利用\n- ε-贪心\n- 上置信界(UCB)\n- 汤普森采样","x":960,"y":590,"width":400,"height":305,"color":"2"},
		{"id":"10","type":"text","text":"# 降维技术\n\n## 主成分分析(PCA)\n- 特征值与特征向量\n- 方差解释率\n\n## 线性判别分析(LDA)\n\n## 流形学习\n- t-SNE\n- UMAP\n- Isomap\n\n## 因子分析","x":160,"y":189,"width":400,"height":165},
		{"id":"16","type":"text","text":"# 自监督学习\n\n## 核心概念\n- 从数据本身生成监督信号\n- 预训练与微调范式\n- 表示学习\n\n## 常用方法\n- 对比学习(Contrastive Learning)\n  - SimCLR\n  - MoCo\n  - BYOL\n- 掩码建模(Masked Modeling)\n  - 掩码图像建模(MIM)\n  - 掩码语言建模(MLM)\n\n## 应用领域\n- 计算机视觉\n- 自然语言处理\n- 多模态学习","x":960,"y":244,"width":400,"height":220,"color":"2"},
		{"id":"13","type":"text","text":"# 半监督与弱监督学习\n\n## 半监督学习方法\n- 自训练(Self-training)\n- 标签传播(Label Propagation)\n- 协同训练(Co-training)\n\n## 弱监督学习\n- 不完全监督\n- 不精确监督\n- 不准确监督","x":1440,"y":189,"width":400,"height":200,"color":"2"},
		{"id":"4","type":"text","text":"# 模型评估\n\n## 评估指标\n- 分类问题：准确率、精确率、召回率、F1值、ROC曲线、AUC\n- 回归问题：MSE、RMSE、MAE、R²\n\n## 验证方法\n- 训练集/测试集分割\n- 交叉验证(Cross-validation)\n- K折交叉验证\n- 留一交叉验证","x":-800,"y":592,"width":400,"height":225,"color":"5"},
		{"id":"12","type":"text","text":"# 模型实践\n\n## 工作流程\n- 问题定义\n- 数据收集\n- 探索性数据分析(EDA)\n- 特征工程\n- 模型训练与评估\n- 超参数调优\n- 模型部署\n\n## 常见工具\n- Scikit-learn\n- Pandas\n- NumPy\n- Matplotlib / Seaborn\n- XGBoost / LightGBM\n- MLflow\n- Optuna","x":360,"y":496,"width":400,"height":297,"color":"5"},
		{"id":"6","type":"text","text":"# 模型调优\n\n## 过拟合与欠拟合\n- 偏差(Bias)与方差(Variance)权衡\n- 学习曲线(Learning curves)\n\n## 正则化方法\n- L1正则化(Lasso)\n- L2正则化(Ridge)\n- Elastic Net\n- 早停(Early stopping)\n- 集成学习(Ensemble learning)","x":-160,"y":606,"width":400,"height":198,"color":"5"},
		{"id":"8","type":"text","text":"# 决策树与集成方法\n\n## 决策树\n- 信息增益\n- 基尼不纯度\n- 剪枝方法\n\n## 集成学习\n- Bagging: 随机森林(Random Forest)\n- Boosting: AdaBoost, Gradient Boosting\n- XGBoost\n- LightGBM\n- CatBoost\n- Stacking","x":840,"y":-635,"width":400,"height":300},
		{"id":"1","type":"text","text":"# 机器学习基础\n\n机器学习是人工智能的一个子领域，研究如何使计算机系统通过经验自动改进。\n\n## 主要类型\n- 监督学习\n- 无监督学习\n- 半监督学习\n- 自监督学习\n- 强化学习\n\n## 基本术语\n- 特征(Features)\n- 标签(Labels)\n- 样本(Samples)\n- 模型(Model)\n- 训练(Training)\n- 推理(Inference)","x":-800,"y":-592,"width":400,"height":335,"color":"1"},
		{"id":"5","type":"text","text":"# 特征工程\n\n\n## 特征选择\n- 过滤法(Filter methods)\n- 包装法(Wrapper methods)\n- 嵌入法(Embedded methods)\n\n## 特征提取\n- 主成分分析(PCA)\n- 线性判别分析(LDA)\n\n## 特征转换\n- 规范化(Normalization)\n- 标准化(Standardization)\n- 离散化(Discretization)\n- 独热编码(One-hot encoding)\n- 缺失值处理","x":-560,"y":171,"width":400,"height":183,"color":"3"},
		{"id":"2","type":"text","text":"# 监督学习\n\n利用标记数据训练模型，使其能够对新的未标记数据进行预测。\n\n## 主要任务\n- 分类(Classification)\n- 回归(Regression)\n\n## 常见算法\n- 线性回归(Linear Regression)\n- 逻辑回归(Logistic Regression)\n- 决策树(Decision Trees)\n- 随机森林(Random Forests)\n- 支持向量机(SVM)\n- K-近邻(KNN)\n- 朴素贝叶斯(Naive Bayes)","x":40,"y":-601,"width":480,"height":232,"color":"2"},
		{"id":"14","type":"text","text":"# 异常检测\n\n## 统计方法\n- Z-score方法\n- 箱线图方法\n\n## 基于密度的方法\n- 局部异常因子(LOF)\n- DBSCAN变体\n\n## 基于距离的方法\n- K-近邻距离\n- 孤立森林(Isolation Forest)\n\n## 基于模型的方法\n- 单类SVM\n- 自编码器","x":1520,"y":-226,"width":400,"height":175},
		{"id":"3","type":"text","text":"# 无监督学习\n\n在无标签数据上训练模型，寻找数据中的结构或模式。\n\n## 主要任务\n- 聚类(Clustering)\n- 降维(Dimensionality Reduction)\n- 异常检测(Anomaly Detection)\n\n## 常见算法\n- K-means聚类\n- 层次聚类(Hierarchical Clustering)\n- DBSCAN\n- 主成分分析(PCA)\n- t-SNE\n- 自编码器(Autoencoders)","x":560,"y":-276,"width":400,"height":300,"color":"2"},
		{"id":"9","type":"text","text":"# 聚类算法\n\n## K-means\n- 簇心选择\n- 评估聚类质量\n- K值选择方法\n\n## 层次聚类\n- 自上而下(Divisive)\n- 自下而上(Agglomerative)\n\n## 密度聚类\n- DBSCAN\n- OPTICS\n\n## 高斯混合模型(GMM)","x":1040,"y":-230,"width":400,"height":210},
		{"id":"15","type":"text","text":"# 推荐系统\n\n## 协同过滤\n- 基于用户的协同过滤\n- 基于物品的协同过滤\n\n## 基于内容的推荐\n\n## 矩阵分解\n- 奇异值分解(SVD)\n- 非负矩阵分解(NMF)\n\n## 混合推荐系统","x":-440,"y":-210,"width":400,"height":201,"color":"3"},
		{"id":"7","type":"text","text":"# 线性回归和逻辑回归\n\n## 线性回归\n- 普通最小二乘法(OLS)\n- 岭回归(Ridge)\n- Lasso回归\n\n## 逻辑回归\n- 二分类逻辑回归\n- 多分类逻辑回归(Softmax)\n\n## 支持向量机(SVM)\n- 线性SVM\n- 核SVM（核函数）","x":40,"y":-193,"width":400,"height":217}
	],
	"edges":[
		{"id":"e1-2","fromNode":"1","fromSide":"right","toNode":"2","toSide":"left","color":"2"},
		{"id":"e1-3","fromNode":"1","fromSide":"right","toNode":"3","toSide":"left","color":"2"},
		{"id":"e1-4","fromNode":"1","fromSide":"bottom","toNode":"4","toSide":"top"},
		{"id":"e1-5","fromNode":"1","fromSide":"bottom","toNode":"5","toSide":"top"},
		{"id":"e2-7","fromNode":"2","fromSide":"bottom","toNode":"7","toSide":"top"},
		{"id":"e1-6","fromNode":"1","fromSide":"bottom","toNode":"6","toSide":"top"},
		{"id":"e17-18","fromNode":"17","fromSide":"right","toNode":"18","toSide":"left"},
		{"id":"e17-15","fromNode":"17","fromSide":"left","toNode":"15","toSide":"bottom"},
		{"id":"1234993d8d09ffdb","fromNode":"5","fromSide":"top","toNode":"7","toSide":"bottom"},
		{"id":"788b61acbd11d62b","fromNode":"4","fromSide":"right","toNode":"6","toSide":"left"},
		{"id":"5562b048b4a1b8d9","fromNode":"5","fromSide":"right","toNode":"10","toSide":"left"},
		{"id":"fc4e827e01e19d88","fromNode":"5","fromSide":"right","toNode":"12","toSide":"top"},
		{"id":"a168830cdc39d220","fromNode":"2","fromSide":"right","toNode":"8","toSide":"left"},
		{"id":"e6cdddaebcf420b9","fromNode":"16","fromSide":"left","toNode":"12","toSide":"right"},
		{"id":"f80b29f6278da8a5","fromNode":"12","fromSide":"bottom","toNode":"4","toSide":"bottom"},
		{"id":"3c80382640c08e21","fromNode":"3","fromSide":"right","toNode":"9","toSide":"left"},
		{"id":"171cd2063ddddf0d","fromNode":"3","fromSide":"right","toNode":"14","toSide":"top"},
		{"id":"6ea0c91f2006e14e","fromNode":"3","fromSide":"bottom","toNode":"10","toSide":"right"},
		{"id":"78e8eed99b315d0d","fromNode":"1","fromSide":"right","toNode":"13","toSide":"top","color":"2"},
		{"id":"c68a64575c89d723","fromNode":"1","fromSide":"right","toNode":"16","toSide":"top","color":"2"},
		{"id":"3dab162c4038b25e","fromNode":"1","fromSide":"right","toNode":"17","toSide":"top","color":"2"},
		{"id":"c94a269538902781","fromNode":"2","fromSide":"right","toNode":"11","toSide":"left"},
		{"id":"c6b0c0bec7c55fd5","fromNode":"2","fromSide":"left","toNode":"15","toSide":"top"}
	]
}