
### 概念

<font style="background-color: salmon; color:black">The process of going back to an earlier or less advanced form or state.</font>

回归分析是一种用于<font style="background-color:salmon; color:black">研究变量之间关系</font>的统计方法，特别是研究一个$X$或多个自变量（也称为解释变量或预测变量）如何影响因变量$Y$（也称为响应变量或被预测变量）的变化。

<font style="background-color:yellow; color:black">回归 = 找出一个“输入”和“数值型输出”之间的规律，建立预测公式。</font>
如，用回归算法尝试估计 $y=2x$ 这个函数，然后预测x=n，y=？

#### 目标

- 总结函数：理解自变量对因变量的影响程度和方向
- 用于预测：预测在给定自变量值的情况下，因变量的可能取值

#### 核心结构
$$Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \cdots + \beta_n X_{ki} + \varepsilon$$
- y 是<font style="background-color:yellow; color:black">因变量</font>
- `x₁, x₂, ..., xₙ` 是<font style="background-color:yellow; color:black">自变量</font>
- `β₀, β₁, β₂, ..., βₙ` 是模型参数（也称为回归系数）
- ε 是<font style="background-color:yellow; color:black">误差项</font>，代表模型无法解释的随机变异
- <font style="background-color:yellow; color:black">拟合优度</font> $R^2$  衡量模型预测效果好坏的一个统计量

#### 回归分析

- 1️⃣ **条件期望** （Conditional Expectation）

公式 $- \mathbb{E}[Y \mid X = x]$， 给定X， 预测Y

回归用于  <font style="background-color:red; color:black">尝试估计</font><font style="background-color:yellow; color:black">条件期望的函数</font>，并使用这个函数预测

为什么是尝试估计，因为 **真实的** $\mathbb{E}[Y \mid X = x]$ **是“不可知的”函数**

举例：
> 观察到：吃冰淇淋多的人，更不容易中暑。
> 问题分析：给定X = 一个人每天吃冰淇淋的次数，预测Y=此人夏天中暑的概率
> 回归分析：估计出函数 $Y = f(X)$ ， 然后使用函数预测。


- 2️⃣ **因果推断** (Causal Inference)

研究方向：如果我主动干预了变量X，Y会发生什么变化

公式：$- \mathbb{E}[Y \mid \text{do}(X=x)]$

回归用于建模 <font style="background-color:yellow; color:black">观测到的相关性。</font>

举例：
> 研究目标：医学团队想验证「吃冰淇淋（$X$）」是否能降低「中暑概率（$Y$）」，证明因果关系
> 实验阶段：
>	把人**随机分组**为：
>		- 处理组（吃冰淇淋）
>		- 对照组（不吃）
> $Y_i = \beta_0 + \beta_1 X_i + \beta_2 Z_{1i} + \beta_3 Z_{2i} + \cdots + \epsilon_i$ 影响中暑有很多变量，如年龄，身体状况，着装，吃冰淇淋$X_i$
> 在控制其他变量后，吃冰淇淋$X_i$对中暑的**边际因果效应估计**
> 回归算法 预估$\beta_1$的值，如果明显为负，因果成立


### 回归分类

#### 简单回归和多元回归

##### **简单回归（Simple  Regression）**
只包含**一个变量**
$$Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i$$

#####  多元回归（Multiple  Regression）
包含 **多个自变量**，**逐步控制、逐个研究**
$$Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \cdots + \beta_k X_{ki} + \varepsilon_i $$

#### 线性回归和逻辑回归
 
##### 简单线性回归 (Simple Linear Regression)
用于预测一个连续的变量

- 最佳拟合 best fit
「最佳拟合」指的是找到一条最能描述 **自变量（X）** 和 **因变量（Y）** 之间关系的线（或平面），这个线就是我们要找的 **回归方程**。


##### OLS回归（Ordinary Least Squares Regression）
普通最小二乘法回归，通过最小化预测值与真实值之间的 <font style="background-color:yellow; color:black">残差平方和</font>，来预估模型参数。

目标： 找到一条直线（或超平面），使得所有数据点的预测误差平方和最小。

$$\text{SSR} = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$
- 实际值 $y_i$
- 预测值  $\hat{y}_i=β_0+β_1x_{i1}+⋯+βpxipy^​i​=β_0​+β_1​ x_{i1​}+⋯+βp​xip​$ 是预测值
- 残差（residual）是实际值与预测值之间的差异

特点：
- 易于理解和解释
- 不需要调参： 只需要提供数据
- 回归解是只需要通过计算得到的
- 准确值会受到**异常值**的极大影响

### 回归算法