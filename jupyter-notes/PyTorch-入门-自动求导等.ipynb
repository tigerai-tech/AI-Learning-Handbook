{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 自动求导"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 梯度跟踪"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T13:29:48.412322Z",
     "start_time": "2025-04-15T13:29:47.539337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个需要梯度的张量\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x ** 2  # y = x^2\n",
    "\n",
    "# 计算梯度\n",
    "y.backward()  # dy/dx = 2x\n",
    "print(x.grad)  # 输出: tensor(4.) (因为 x=2, 2*2=4)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 多变量梯度"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T13:29:51.145023Z",
     "start_time": "2025-04-15T13:29:51.139092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y = x.sum() ** 2  # y = (x1 + x2)^2\n",
    "\n",
    "y.backward()\n",
    "print(x.grad)  # x^2的导数是2x， 2*（1+2）=6"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6., 6.])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 动态计算图  \n",
    "PyTorch 的计算图是动态的，每次前向传播都会构建一个新图：\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T13:29:57.984356Z",
     "start_time": "2025-04-15T13:29:57.978736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward(x):\n",
    "    return x ** 2 + 2 * x + 1\n",
    "\n",
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = forward(x)\n",
    "y.backward()\n",
    "print(x.grad)  # 输出: tensor(8.) (因为 dy/dx=2x+2=8)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 梯度积累 与 清零\n",
    "PyTorch 默认会累加梯度，训练时需手动清零："
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T13:30:07.400392Z",
     "start_time": "2025-04-15T13:30:07.392438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "# 第一次计算\n",
    "y1 = x ** 2\n",
    "y1.backward()\n",
    "print(x.grad)  # tensor(2.)  2*x\n",
    "\n",
    "# 清零梯度\n",
    "# x.grad.zero_()\n",
    "\n",
    "# 第二次计算（梯度会累加）\n",
    "y2 = x ** 3\n",
    "y2.backward()\n",
    "print(x.grad)  # tensor(5.) 没清0: (2*1 + 3*1^2=5)； 梯度清过0: 3*1^2=3\n",
    "\n",
    "# 清零梯度\n",
    "x.grad.zero_()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(5.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 阻止梯度跟踪\n",
    "\n",
    "detach() 分离张量，使其不参与梯度计算：\n",
    "\n",
    "```python\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x ** 2\n",
    "z = y.detach()  # z 不参与梯度计算\n",
    "\n",
    "z.backward()  # 报错！z 无梯度跟踪\n",
    "\n",
    "## 临时禁用梯度计算：\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "with torch.no_grad():\n",
    "    y = x ** 2  # y 不记录计算图\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "####  高阶导数"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T13:30:11.263015Z",
     "start_time": "2025-04-15T13:30:11.258197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x ** 3\n",
    "\n",
    "# 一阶导数\n",
    "grad1 = torch.autograd.grad(y, x, create_graph=True)  # dy/dx=3x^2=12\n",
    "print(grad1[0])  # tensor(12.)\n",
    "\n",
    "# 二阶导数\n",
    "grad2 = torch.autograd.grad(grad1[0], x)  # d²y/dx²=3*2x=12\n",
    "print(grad2[0])  # tensor(12.)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12., grad_fn=<MulBackward0>)\n",
      "tensor(12.)\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ]
}
